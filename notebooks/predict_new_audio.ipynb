{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload a new wav file and see how the model works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "filename = '/Users/rblc/code/iamrblc/laica/xgboost_model.pkl'\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_audio = '/Users/rblc/code/iamrblc/laica/audio/snippets_from_yt/chiuahuagrowl.mp3'\n",
    "actual_label = 'growl'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "audio, sr = librosa.load(new_audio)\n",
    "\n",
    "# Normalize the audio with librosa\n",
    "audio = librosa.util.normalize(audio)\n",
    "\n",
    "# Make dataframe\n",
    "df = pd.DataFrame({'audio': [audio]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rblc/.pyenv/versions/3.10.6/envs/laica/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=863\n",
      "  return f(*args, **kwargs)\n",
      "/Users/rblc/.pyenv/versions/3.10.6/envs/laica/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=432\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def extract_features(row):\n",
    "    y, sr = row['audio'], 22050\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    tonal_centroid = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    roll_off_frequency = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    chroma_vqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    rms_energy = librosa.feature.rms(y=y)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y)\n",
    "    \n",
    "    return mfcc, spectral_centroid, tonal_centroid, spectral_bandwidth, spectral_contrast, spectral_flatness, roll_off_frequency, chroma_stft, chroma_cqt, chroma_cens, chroma_vqt, mel_spectrogram, rms_energy, tonnetz, zero_crossing_rate\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "features = df.apply(extract_features, axis=1)\n",
    "         \n",
    "# Add the features to the dataframe as new columns\n",
    "df['mfcc'] = features.apply(lambda x: x[0])                   \n",
    "df['spectral_centroid'] = features.apply(lambda x: x[1])\n",
    "df['tonal_centroid'] = features.apply(lambda x: x[2])\n",
    "df['spectral_bandwidth'] = features.apply(lambda x: x[3])\n",
    "df['spectral_contrast'] = features.apply(lambda x: x[4])\n",
    "df['spectral_flatness'] = features.apply(lambda x: x[5])\n",
    "df['roll_off_frequency'] = features.apply(lambda x: x[6])\n",
    "df['chroma_stft'] = features.apply(lambda x: x[7])\n",
    "df['chroma_cqt'] = features.apply(lambda x: x[8])\n",
    "df['chroma_cens'] = features.apply(lambda x: x[9])\n",
    "df['chroma_vqt'] = features.apply(lambda x: x[10])\n",
    "df['mel_spectrogram'] = features.apply(lambda x: x[11])\n",
    "df['rms_energy'] = features.apply(lambda x: x[12])\n",
    "df['tonnetz'] = features.apply(lambda x: x[13])\n",
    "df['zero_crossing_rate'] = features.apply(lambda x: x[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['audio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_median</th>\n",
       "      <th>spectral_centroid_median</th>\n",
       "      <th>tonal_centroid_median</th>\n",
       "      <th>spectral_bandwidth_median</th>\n",
       "      <th>spectral_contrast_median</th>\n",
       "      <th>spectral_flatness_median</th>\n",
       "      <th>roll_off_frequency_median</th>\n",
       "      <th>chroma_stft_median</th>\n",
       "      <th>chroma_cqt_median</th>\n",
       "      <th>chroma_cens_median</th>\n",
       "      <th>chroma_vqt_median</th>\n",
       "      <th>mel_spectrogram_median</th>\n",
       "      <th>rms_energy_median</th>\n",
       "      <th>tonnetz_median</th>\n",
       "      <th>zero_crossing_rate_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-104.185616</td>\n",
       "      <td>1427.23635</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>1706.92241</td>\n",
       "      <td>21.857811</td>\n",
       "      <td>0.00211</td>\n",
       "      <td>2083.337402</td>\n",
       "      <td>0.142177</td>\n",
       "      <td>0.431883</td>\n",
       "      <td>0.209289</td>\n",
       "      <td>0.431883</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.195681</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.075684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mfcc_median  spectral_centroid_median  tonal_centroid_median  \\\n",
       "0  -104.185616                1427.23635               0.005199   \n",
       "\n",
       "   spectral_bandwidth_median  spectral_contrast_median  \\\n",
       "0                 1706.92241                 21.857811   \n",
       "\n",
       "   spectral_flatness_median  roll_off_frequency_median  chroma_stft_median  \\\n",
       "0                   0.00211                2083.337402            0.142177   \n",
       "\n",
       "   chroma_cqt_median  chroma_cens_median  chroma_vqt_median  \\\n",
       "0           0.431883            0.209289           0.431883   \n",
       "\n",
       "   mel_spectrogram_median  rms_energy_median  tonnetz_median  \\\n",
       "0                  0.0011           0.195681        0.005199   \n",
       "\n",
       "   zero_crossing_rate_median  \n",
       "0                   0.075684  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_nested_stats(df, col_name):\n",
    "\n",
    "    # Calculate median of first nested array only\n",
    "    nested_median_func = lambda x: np.median(x[0])\n",
    "    median_values = np.array(df[col_name].apply(nested_median_func).tolist())\n",
    "    median_col_name = f\"{col_name}_median\"\n",
    "    df[median_col_name] = pd.DataFrame(median_values)\n",
    "    \n",
    "    return df\n",
    "\n",
    "for column_name in df.columns:\n",
    "    if isinstance(df[column_name][0], np.ndarray):\n",
    "        df = calculate_nested_stats(df, column_name)\n",
    "        df = df.drop(columns = column_name)\n",
    "        \n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaler\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided snippet is a growl. The predicted probabilities:\n",
      "bark: 0.312979\n",
      "growl: 0.000336\n",
      "pant: 0.151823\n",
      "whine: 0.529609\n",
      "yelp: 0.005253\n"
     ]
    }
   ],
   "source": [
    "encoded_classes = {'bark': 0, 'growl': 1, 'pant': 2, 'whine': 3, 'yelp': 4}\n",
    "\n",
    "# Run the model on the new audio file\n",
    "prediction = model.predict(df)\n",
    "\n",
    "# Calculate the probabilities of each class\n",
    "proba = model.predict_proba(df)\n",
    "\n",
    "# Invert the encoded classes dictionary to get a mapping of class indices to their labels\n",
    "class_labels = {v: k for k, v in encoded_classes.items()}\n",
    "\n",
    "print(f\"The provided snippet is a {actual_label}. The predicted probabilities:\")\n",
    "for i, p in enumerate(proba[0]):\n",
    "    class_label = class_labels[i]\n",
    "    print(f\"{class_label}: {p:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
