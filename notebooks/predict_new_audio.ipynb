{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload a new wav file and see how the model works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "from librosa.effects import time_stretch, pitch_shift\n",
    "import audiomentations as AA\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "filename = '/Users/rblc/code/iamrblc/laica/xgboost_model.pkl'\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_audio = '/Users/rblc/code/iamrblc/laica/audio/snippets_test_set/bark_00060.wav'\n",
    "actual_label = 'bark'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "audio, sr = librosa.load(new_audio)\n",
    "\n",
    "# Normalize the audio with librosa\n",
    "audio = librosa.util.normalize(audio)\n",
    "\n",
    "# Make dataframe\n",
    "df = pd.DataFrame({'audio': [audio]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rblc/.pyenv/versions/3.10.6/envs/laica/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=1012\n",
      "  return f(*args, **kwargs)\n",
      "/Users/rblc/.pyenv/versions/3.10.6/envs/laica/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=506\n",
      "  return f(*args, **kwargs)\n",
      "/Users/rblc/.pyenv/versions/3.10.6/envs/laica/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=253\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def extract_features(row):\n",
    "    y, sr = row['audio'], 22050\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    tonal_centroid = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    roll_off_frequency = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    chroma_vqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    rms_energy = librosa.feature.rms(y=y)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y)\n",
    "    \n",
    "    return mfcc, spectral_centroid, tonal_centroid, spectral_bandwidth, spectral_contrast, spectral_flatness, roll_off_frequency, chroma_stft, chroma_cqt, chroma_cens, chroma_vqt, mel_spectrogram, rms_energy, tonnetz, zero_crossing_rate\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "features = df.apply(extract_features, axis=1)\n",
    "         \n",
    "# Add the features to the dataframe as new columns\n",
    "df['mfcc'] = features.apply(lambda x: x[0])                   \n",
    "df['spectral_centroid'] = features.apply(lambda x: x[1])\n",
    "df['tonal_centroid'] = features.apply(lambda x: x[2])\n",
    "df['spectral_bandwidth'] = features.apply(lambda x: x[3])\n",
    "df['spectral_contrast'] = features.apply(lambda x: x[4])\n",
    "df['spectral_flatness'] = features.apply(lambda x: x[5])\n",
    "df['roll_off_frequency'] = features.apply(lambda x: x[6])\n",
    "df['chroma_stft'] = features.apply(lambda x: x[7])\n",
    "df['chroma_cqt'] = features.apply(lambda x: x[8])\n",
    "df['chroma_cens'] = features.apply(lambda x: x[9])\n",
    "df['chroma_vqt'] = features.apply(lambda x: x[10])\n",
    "df['mel_spectrogram'] = features.apply(lambda x: x[11])\n",
    "df['rms_energy'] = features.apply(lambda x: x[12])\n",
    "df['tonnetz'] = features.apply(lambda x: x[13])\n",
    "df['zero_crossing_rate'] = features.apply(lambda x: x[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['audio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_median</th>\n",
       "      <th>spectral_centroid_median</th>\n",
       "      <th>tonal_centroid_median</th>\n",
       "      <th>spectral_bandwidth_median</th>\n",
       "      <th>spectral_contrast_median</th>\n",
       "      <th>spectral_flatness_median</th>\n",
       "      <th>roll_off_frequency_median</th>\n",
       "      <th>chroma_stft_median</th>\n",
       "      <th>chroma_cqt_median</th>\n",
       "      <th>chroma_cens_median</th>\n",
       "      <th>chroma_vqt_median</th>\n",
       "      <th>mel_spectrogram_median</th>\n",
       "      <th>rms_energy_median</th>\n",
       "      <th>tonnetz_median</th>\n",
       "      <th>zero_crossing_rate_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-388.905273</td>\n",
       "      <td>1478.740651</td>\n",
       "      <td>0.013222</td>\n",
       "      <td>1632.531612</td>\n",
       "      <td>20.918405</td>\n",
       "      <td>0.00227</td>\n",
       "      <td>2164.086914</td>\n",
       "      <td>0.164753</td>\n",
       "      <td>0.353205</td>\n",
       "      <td>0.196019</td>\n",
       "      <td>0.353205</td>\n",
       "      <td>0.076653</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>0.013222</td>\n",
       "      <td>0.07251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mfcc_median  spectral_centroid_median  tonal_centroid_median  \\\n",
       "0  -388.905273               1478.740651               0.013222   \n",
       "\n",
       "   spectral_bandwidth_median  spectral_contrast_median  \\\n",
       "0                1632.531612                 20.918405   \n",
       "\n",
       "   spectral_flatness_median  roll_off_frequency_median  chroma_stft_median  \\\n",
       "0                   0.00227                2164.086914            0.164753   \n",
       "\n",
       "   chroma_cqt_median  chroma_cens_median  chroma_vqt_median  \\\n",
       "0           0.353205            0.196019           0.353205   \n",
       "\n",
       "   mel_spectrogram_median  rms_energy_median  tonnetz_median  \\\n",
       "0                0.076653           0.008169        0.013222   \n",
       "\n",
       "   zero_crossing_rate_median  \n",
       "0                    0.07251  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_nested_stats(df, col_name):\n",
    "\n",
    "    # Calculate median of first nested array only\n",
    "    nested_median_func = lambda x: np.median(x[0])\n",
    "    median_values = np.array(df[col_name].apply(nested_median_func).tolist())\n",
    "    median_col_name = f\"{col_name}_median\"\n",
    "    df[median_col_name] = pd.DataFrame(median_values)\n",
    "    \n",
    "    return df\n",
    "\n",
    "for column_name in df.columns:\n",
    "    if isinstance(df[column_name][0], np.ndarray):\n",
    "        df = calculate_nested_stats(df, column_name)\n",
    "        df = df.drop(columns = column_name)\n",
    "        \n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided snippet is a bark. The predicted probabilities:\n",
      "bark: 0.493412\n",
      "growl: 0.000423\n",
      "pant: 0.000278\n",
      "whine: 0.505805\n",
      "yelp: 0.000081\n"
     ]
    }
   ],
   "source": [
    "encoded_classes = {'bark': 0, 'growl': 1, 'pant': 2, 'whine': 3, 'yelp': 4}\n",
    "\n",
    "# Run the model on the new audio file\n",
    "prediction = model.predict(df)\n",
    "\n",
    "# Calculate the probabilities of each class\n",
    "proba = model.predict_proba(df)\n",
    "\n",
    "# Invert the encoded classes dictionary to get a mapping of class indices to their labels\n",
    "class_labels = {v: k for k, v in encoded_classes.items()}\n",
    "\n",
    "print(f\"The provided snippet is a {actual_label}. The predicted probabilities:\")\n",
    "for i, p in enumerate(proba[0]):\n",
    "    class_label = class_labels[i]\n",
    "    print(f\"{class_label}: {p:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
